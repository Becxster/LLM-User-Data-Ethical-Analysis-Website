<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Case Study: LLMs & User Privacy</title>

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@500;600&display=swap"
        rel="stylesheet"
    />

    <!-- Bootstrap CSS -->
    <link
        href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
        rel="stylesheet"
    />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/styles.css" />
</head>
<body data-bs-spy="scroll" data-bs-target="#sectionNav" data-bs-offset="90" tabindex="0">
    <!-- Navbar -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top glass-nav">
        <div class="container">
            <a class="navbar-brand fw-semibold tracking-wide" href="#top">
                <span class="brand-accent">●</span> Case Study: California AI Chatbot Law SB-243
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                    data-bs-target="#navbarContent" aria-controls="navbarContent"
                    aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarContent">
                <ul class="navbar-nav ms-auto align-items-lg-center">
                    <li class="nav-item">
                        <a class="nav-link" href="#overview">Description</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#ethical-analysis">Ethical analysis</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#societal-impact">Societal impact</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#references">References</a>
                    </li>
                    <li class="nav-item d-none d-lg-block ms-3">
                        <span class="badge rounded-pill bg-accent-soft text-accent fw-medium">
                            Informational only
                        </span>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Hero / Intro with background image -->
    <header id="top" class="hero-section d-flex align-items-center">
        <div class="hero-overlay"></div>
        <div class="container position-relative">
            <div class="row align-items-center g-4">
                <div class="col-lg-7">
                    <p class="eyebrow mb-2">Digital ethics case study</p>
                    <h1 class="display-4 hero-title mb-3">
                        Private Right of Action Against AI: Ethics of California's SLB-243
                    </h1>
                    <p class="hero-subtitle mb-4">
                        <!-- Replace with a 2–3 sentence summary. -->
                        This site presents an in-depth case study on the user safety and privacy issues surrounding Large Language Models (LLMs),
                        which led to the passing of Senate Bill 243 (SB-243) in California. Ethical considerations are analyzed, and the broader societal
                        impacts are explored along with possible solutions.
                    </p>

                    <div class="d-flex flex-wrap gap-2 mb-3">
                        <a href="#overview" class="btn btn-accent btn-lg">
                            Start with the case description
                        </a>
                        <a href="#ethical-analysis" class="btn btn-outline-light btn-lg">
                            Jump to ethical analysis
                        </a>
                    </div>

                    <div class="keyword-pills d-flex flex-row flex-nowrap overflow-auto pt-1">
                        <span class="pill">#ethics</span>
                        <span class="pill">#data</span>
                        <span class="pill">#privacy</span>
                        <span class="pill">#accountability</span>
                        <span class="pill">#governance</span>
                        <span class="pill">#fairness</span>
                        <!-- Edit / replace tags as needed -->
                    </div>
                </div>
                <div class="col-lg-5">
                    <div class="hero-card shadow-lg border-0">
                        <div class="card-body">
                            <h2 class="h5 mb-3">At a glance</h2>
                            <dl class="row g-2 small mb-0">
                                <dt class="col-5 text-muted">Topic</dt>
                                <dd class="col-7">California's SB-243 and chatbot safety</dd>

                                <dt class="col-5 text-muted">Core dilemma</dt>
                                <dd class="col-7">Should users be able to sue chatbot organizations for harmful effects of conversations their chatbots produced?</dd>

                                <dt class="col-5 text-muted">Main stakeholders</dt>
                                <dd class="col-7">AI Users, AI Companies, State & Federal Regulators</dd>

                                <dt class="col-5 text-muted">Focus</dt>
                                <dd class="col-7">Description, ethical analysis, societal impact.</dd>
                            </dl>
                            <hr class="my-3" />
                            <p class="text-muted mb-0 tiny">
                                This case study is for educational purposes only and does not constitute legal advice.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Parallax band: Why this case matters -->
    <section class="parallax-section parallax-impact text-light">
        <div class="parallax-overlay"></div>
        <div class="container position-relative py-5">
            <div class="row justify-content-center text-center">
                <div class="col-lg-9">
                    <p class="eyebrow mb-2">Why this matters</p>
                    <h2 class="h2 mb-3">A new frontier for AI safety legislation</h2>
                    <p class="lead mb-0">
                        Senate Bill 243 (SB-243) makes California the first state to enact an AI chatbot law that includes a private right of action. This means users themselves can sue chatbot operators for malpractice. This kind of AI chatbot legislation is <b>unprecedented</b> in the United States.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Main Content -->
    <main class="container content-container mb-5">
        <div class="row g-4">
            <!-- Sidebar navigation -->
            <aside class="col-xl-3 d-none d-xl-block">
                <nav id="sectionNav" class="sticky-toc">
                    <p class="toc-label text-uppercase text-muted mb-2">On this page</p>
                    <div class="list-group list-group-flush small">
                        <a class="list-group-item list-group-item-action" href="#overview">
                            1. Description of case study
                        </a>
                        <a class="list-group-item list-group-item-action" href="#ethical-analysis">
                            2. Ethical analysis
                        </a>
                        <a class="list-group-item list-group-item-action" href="#societal-impact">
                            3. Societal impact / solutions
                        </a>
                        <a class="list-group-item list-group-item-action" href="#references">
                            4. References & resources
                        </a>
                    </div>
                </nav>
            </aside>

            <!-- Main sections -->
            <section class="col-xl-9">
                <!-- Description / Case overview -->
                <section id="overview" class="content-section">
                    <p class="section-kicker">Section 1</p>
                    <h2 class="section-title">Description of the case study: SB-243</h2>
                    <p class="section-intro">
                        With the boom of AI companies in the US, thousands of LLM companies have emerged, offering chatbot services to anyone with access to the internet. With their high market potentials, chatbots have evolved at a pace that policy and regulation cannot match. Thus, safety rules for chatbot operators have been lenient, leading to harmful scenarios.
                        In July, Senator Alex Padilla of California held a press conference with Ms. Garcia, the mother of Sewal Setzer III, who died from suicide after interaction with a CharacterAI chatbot. Here, they called for the passage of <b>Senate Bill 243 (SB-243)</b>, a California Senate Bill yielding chatbot users the right to file civil suits against chatbot operators for self-harm damages incurred through chatbot conversations. This bill aims to enforce stronger safety guardrails on chatbots when interacting with children, particularly on the ability of the chatbots to encourage self-harm and produce sexually explicit material.
                        New York, Maine, Utah, Nevada, Illinois have all instituted chatbot laws in 2025 relating to disclosure requirements for AI chatbot operators, measures to detect and address self-harmful ideation in users, and other safety guardrails — but none of these gave users the power of private right of action against chatbot operators.
                    </p>

                    <div class="row g-4">
                        <div class="col-lg-7">
                            <div class="card shadow-sm border-0">
                                <div class="card-body">
                                    <h3 class="h5 mb-3">Background</h3>
                                    <p>
                                        Lawsuits against harmful interactions between AI chatbots and minors have accumulated with widepread user adoption of conversational LLMs. <i>Raine v. OpenAI</i> was a lawsuit filed in Aug 2025 by the parents of 16-year-old Adam Raine, who committed suicide after prompting ChatGPT’s LLM model to provide him with information about how to tie a noose and a step-by-step guide to hang himself. The Chatbot also showed support for the child’s suicidal ideations and entertained his suicidal thoughts.
                                        There have also been lawsuits filed to the company CharacterTechnologies, for conversations between their chatbot Character.AI and minors. Two of these suits include suicides (14-year-old Sewell Setzer III and 13-year-old Juliana Peralta), and claim that the chatbot encouraged sexualized conversations and manipulated vulnerable teenagers.
                                        SB-243 makes California the first state to enact an AI chatbot law that includes a private right of action. This means users themselves can sue chatbot operators for malpractice. This is unprecedented.
                                    </p>
                                    <h3 class="h6 text-muted text-uppercase mt-4 mb-2">Key events</h3>
                                    <ol class="small mb-0">
                                        <li>October 2024: Megan Garcia files federal lawsuit against CharacterTechnologies on 11 legal claims, including wrongful death of her son, Sewell Setzer III.</li>
                                        <li>May 2025: New York becomes the first U.S. state to require safety guardrails for AI companion systems.</li>
                                        <li>August 2025: Raine v. OpenAI is filed in the San Francisco Superior Court</li>
                                        <li>October 2025: Senate Bill 243 signed into law by California Governor Gavin Newsom</li>
                                    </ol>
                                </div>
                            </div>
                        </div>

                        <div class="col-lg-5">
                            <div class="scrollable-card shadow-sm border-0 mb-3">
                                <div class="card-body">
                                    <h3 class="h6 text-muted text-uppercase mb-2">Stakeholders</h3>
                                    <p class="small">
                                        SB-243 creates a legal precedent for future AI-restrictive policies.
                                    </p>
                                    <ul class="small mb-0">
                                        <li><span class="fw-semibold">Primary users:</span> Users of chatbots, especially companion AI chatbots.</li>
                                        <li><span class="fw-semibold">Organization:</span> Companion chatbot operators, including CharacterTechnologies.</li>
                                        <li><span class="fw-semibold">Third parties:</span> Attorneys, Courts</li>
                                        <li><span class="fw-semibold">Regulators / public:</span> California State Sentate, Office of Suicide Prevention</li>
                                        <li><span class="fw-semibold">Future stakeholders:</span> LLM companies, other US state legislatures</li>
                                    </ul>
                                </div>
                            </div>

                            <div class="summary-box p-3">
                                <p class="tiny text-muted text-uppercase mb-1">Core question</p>
                                <p class="mb-0">
                                    <i>“Is it ethically permissible to give chatbot users the power to sue chatbot operators for damages even though there is not a human generating the conversations?”</i>
                                </p>
                            </div>
                        </div>
                    </div>

                                    <!-- Regulatory & policy requirements related to the case -->
                <section class="mt-4" id="disclosure-safety-requirements">
                    <div class="card shadow-sm border-0">
                        <div class="card-body">
                            <h3 class="h5 mb-3">Regulatory requirements relevant to this case</h3>
                            <p class="small text-muted mb-3">
                                This section summarizes key statutory and policy obligations that shape how
                                chatbot operators must design and run their systems, particularly for minors
                                and users expressing suicidal ideation.
                            </p>

                            <div class="row g-4">
                                <div class="col-md-6">
                                    <h4 class="h6 text-uppercase text-muted mb-2">Disclosure requirements</h4>
                                    <ul class="small mb-0">
                                        <li>
                                            When a reasonable person could believe they are interacting with a human,
                                            operators must clearly disclose that the chatbot is an AI system.
                                        </li>
                                        <li class="mt-1">
                                            If the operator knows a user is a minor, they must disclose that the user
                                            is interacting with AI and provide reminders at least every three hours
                                            that the bot is not human and that the user should take a break.
                                        </li>
                                        <li class="mt-1">
                                            Platforms must inform users that companion chatbots may not be appropriate
                                            for some minors.
                                        </li>
                                    </ul>
                                </div>

                                <div class="col-md-6">
                                    <h4 class="h6 text-uppercase text-muted mb-2">Safety protocols</h4>
                                    <ul class="small mb-0">
                                        <li>
                                            Operators must implement and maintain protocols to detect and prevent
                                            content related to suicidal ideation, suicide, or self-harm, and must
                                            provide notifications directing users to crisis service providers when
                                            users express these ideas. These protocols must be published on the
                                            operator’s website.
                                        </li>
                                        <li class="mt-1">
                                            For users known to be minors, operators must take measures to prevent
                                            chatbots from generating sexually explicit visual content or encouraging
                                            minors to engage in sexually explicit conduct.
                                        </li>
                                    </ul>
                                </div>
                            </div>

                            <hr class="my-4" />

                            <div class="row g-4">
                                <div class="col-md-7">
                                    <h4 class="h6 text-uppercase text-muted mb-2">Annual reporting</h4>
                                    <p class="small mb-2">
                                        Operators must submit annual reports to the state Office of Suicide Prevention
                                        (OSP), excluding any user identifiers or personal information, for publication
                                        on the OSP website. Reports must include:
                                    </p>
                                    <ul class="small mb-0">
                                        <li>The number of crisis-service referral notifications issued in the preceding year.</li>
                                        <li>Protocols for detecting, removing, and responding to users’ suicidal ideation.</li>
                                        <li>Protocols prohibiting chatbot responses about suicidal ideation or actions.</li>
                                    </ul>
                                </div>
                                <div class="col-md-5">
                                    <h4 class="h6 text-uppercase text-muted mb-2">Enforcement</h4>
                                    <p class="small mb-0">
                                        Individuals may bring a civil action for injunctive relief, with statutory
                                        damages of at least <span class="fst-italic">$1,000</span> per violation and
                                        reasonable attorneys’ fees and costs.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                </section>

                <!-- Ethical analysis -->
                <section id="ethical-analysis" class="content-section">
                    <p class="section-kicker">Section 2</p>
                    <h2 class="section-title">Ethical analysis</h2>
                    <p class="section-intro">
                        Analyze the case using one or more ethical frameworks. You can compare the conclusions that
                        different frameworks yield and explain how they support or challenge specific decisions.
                    </p>

                    <!-- Tabs for frameworks -->
                    <ul class="nav nav-pills mb-3" id="ethicsTabs" role="tablist">
                        <li class="nav-item" role="presentation">
                            <button class="nav-link active" id="tab-consequentialism" data-bs-toggle="pill"
                                    data-bs-target="#panel-consequentialism" type="button" role="tab"
                                    aria-controls="panel-consequentialism" aria-selected="true">
                                Consequentialism
                            </button>
                        </li>
                        <li class="nav-item" role="presentation">
                            <button class="nav-link" id="tab-deontology" data-bs-toggle="pill"
                                    data-bs-target="#panel-deontology" type="button" role="tab"
                                    aria-controls="panel-deontology" aria-selected="false">
                                Deontology
                            </button>
                        </li>
                        <li class="nav-item" role="presentation">
                            <button class="nav-link" id="tab-virtue" data-bs-toggle="pill"
                                    data-bs-target="#panel-virtue" type="button" role="tab"
                                    aria-controls="panel-virtue" aria-selected="false">
                                Virtue ethics
                            </button>
                        </li>
                    </ul>

                    <div class="tab-content mb-4">
                        <div class="tab-pane fade show active" id="panel-consequentialism" role="tabpanel"
                             aria-labelledby="tab-consequentialism">
                            <div class="card shadow-sm border-0">
                                <div class="card-body">
                                    <h3 class="h5 mb-3">Consequentialist analysis</h3>
                                    <p>
                                        [Describe outcomes for each stakeholder and overall welfare. Who benefits?
                                        Who is harmed? Are harms justified by benefits, and by what standard?]
                                    </p>
                                </div>
                            </div>
                        </div>
                        <div class="tab-pane fade" id="panel-deontology" role="tabpanel"
                             aria-labelledby="tab-deontology">
                            <div class="card shadow-sm border-0">
                                <div class="card-body">
                                    <h3 class="h5 mb-3">Deontological analysis</h3>
                                    <p>
                                        [Discuss duties, rights, and constraints. Does the case involve broken promises,
                                        violations of privacy, unfair treatment, or lack of consent?]
                                    </p>
                                </div>
                            </div>
                        </div>
                        <div class="tab-pane fade" id="panel-virtue" role="tabpanel"
                             aria-labelledby="tab-virtue">
                            <div class="card shadow-sm border-0">
                                <div class="card-body">
                                    <h3 class="h5 mb-3">Virtue ethics analysis</h3>
                                    <p>
                                        [Ask what the actions in this case reveal about the character of individuals
                                        and institutions. Which virtues (e.g., honesty, justice, care) are upheld or
                                        compromised?]
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Ethical tensions -->
                    <div class="row g-4">
                        <div class="col-md-7">
                            <div class="card shadow-sm border-0">
                                <div class="card-body">
                                    <h3 class="h5 mb-3">Key ethical tensions</h3>
                                    <ul class="mb-0">
                                        <li>[Tension 1: e.g., individual privacy vs. organizational efficiency]</li>
                                        <li>[Tension 2: e.g., transparency vs. security]</li>
                                        <li>[Tension 3: e.g., short-term gains vs. long-term trust]</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-5">
                            <div class="quote-box h-100 d-flex flex-column justify-content-center">
                                <p class="tiny text-muted text-uppercase mb-2">Pull quote</p>
                                <p class="mb-0">
                                    “Replace this with a concise sentence that captures your ethical conclusion,
                                    or a key claim from an assigned reading.”
                                </p>
                            </div>
                        </div>
                    </div>

                    <div class="alert alert-secondary mt-4 small" role="alert">
                        Make explicit normative claims (e.g., “The organization should…”). For each claim, briefly
                        justify it using the frameworks above and concrete facts from the case description.
                    </div>
                </section>

                <!-- Parallax band 2: Societal scale
                <section class="parallax-section parallax-solutions text-light">
                    <div class="parallax-overlay"></div>
                    <div class="container position-relative py-5">
                        <div class="row justify-content-center text-center">
                            <div class="col-lg-10">
                                <p class="eyebrow mb-2">Beyond a single case</p>
                                <h2 class="h2 mb-3">From individual decisions to systemic patterns</h2>
                                <p class="mb-0">
                                    [Briefly link this case to patterns identified in Paper 1 or Paper 2:
                                    recurring failures, structural risks, or systemic incentives.]
                                </p>
                            </div>
                        </div>
                    </div>
                </section> -->

                <!-- Societal impact / solutions -->
                <section id="societal-impact" class="content-section">
                    <p class="section-kicker">Section 3</p>
                    <h2 class="section-title">Societal impact</h2>
                    <p class="section-intro">
                        The impact of SB-243 for residents of California and chatbot companies in general is extensive, and sets a policy framework for regulating chatbots more widely in the United States.
                        Four areas of societal impacts likely include safer interactions between AI and the public, higher trust in AI among California residents, higher development
                        and compliance costs for chatbot operators, and a potential reduction in AI-induced suicides & emotional distress.
                    </p>

                    <div class="row g-4 mb-4">
                        <div class="col-md-6">
                            <h3 class="h5 mb-3">Broader societal impact</h3>
                                <p><b class="h6">1. Impact on California residents: Increased safety and trust in AI companion chatbot interactions</b> 
                                <ul>
                                    <li>The passing of SB-243 represents a societal acceptance that AI is no longer a neutral tool and instead has the capacity to do both good and harm</li>
                                    <li>This law therefore emphasizes that AI must have checks and meet safety standards, just like medical devices and transportation vehicles</li>
                                    <li>AI has become so powerful that we are now witnessing AI-mediated social relationships and chatbots are now being used as sources of comfort for teens, and thus must be held in check and adhere to a certain set of standards, similar to a therapist</li>
                                    <li>This legislation represents the beginning of a movement that aims to make AI safer</li>
                                    <li>Will allow more people to place their families’ trust in AI, knowing that their data is secure and that AI will respond responsibly, especially if their children use it</li>
                                </ul></p>
                                <p><b class="h6">2. Impact on chatbot operators: Higher development and compliance costs</b> 
                                <ul>
                                    <li>AI companies will have to add further costs and software to adhere to the policies SB-243 requires</li>
                                    <li>Probably won’t impact large companies but these costs could cause small startups to avoid companion chatbots altogether</li>
                                    <li>This bill emphasizes the need for responsible innovation, not just speed</li>
                                </ul></p>
                                <p><b class="h6">3. Impact in the long-term: Chatbot companies will be pressured to prioritize safety over market entry</b> 
                                <ul>
                                    <li>With the checks that this bill provides, the suicides mentioned in previous cases (that led to the creation of SB-243) could be avoided in the future</li>
                                </ul></p>
                        </div>
                        <!-- <div class="col-md-6">
                            <h3 class="h5 mb-3">Potential solutions / interventions</h3>
                            <ul class="mb-0">
                                <li>[Organizational policies or design changes]</li>
                                <li>[Regulatory or legal reforms]</li>
                                <li>[Transparency, auditing, or accountability mechanisms]</li>
                            </ul>
                        </div> -->
                    </div>

                    <!-- Scrollable comparison card -->
                    <!-- <div class="scrollable-card shadow-sm border-0 mb-4">
                        <div class="card-body">
                            <h3 class="h6 text-muted text-uppercase mb-2">Comparing solutions</h3>
                            <p class="small mb-3">
                                [Use this space like a mini-matrix: compare 2–3 solutions by feasibility, impact,
                                and ethical strength. This is a good place to bring in arguments from Paper 1 / Paper 2.]
                            </p>
                            <div class="row small fw-medium text-muted mb-2">
                                <div class="col-5">Solution</div>
                                <div class="col-3">Feasibility</div>
                                <div class="col-4">Ethical strengths / risks</div>
                            </div>
                            <div class="row small mb-1">
                                <div class="col-5">[Solution A]</div>
                                <div class="col-3">[e.g., High]</div>
                                <div class="col-4">[Key strengths / major risk]</div>
                            </div>
                            <div class="row small mb-1">
                                <div class="col-5">[Solution B]</div>
                                <div class="col-3">[e.g., Medium]</div>
                                <div class="col-4">[Key strengths / major risk]</div>
                            </div>
                            <div class="row small">
                                <div class="col-5">[Solution C]</div>
                                <div class="col-3">[e.g., Low]</div>
                                <div class="col-4">[Key strengths / major risk]</div>
                            </div>
                        </div>
                    </div> -->
                </section>

                <!-- References -->
                <section id="references" class="content-section">
                    <p class="section-kicker">Section 4</p>
                    <h2 class="section-title">References & resources</h2>
                    <p class="section-intro">
                        List any news articles, academic papers, course readings, and policy documents you drew on.
                        Format the citations according to your course requirements.
                    </p>

                    <div class="card shadow-sm border-0">
                        <div class="card-body">
                            <ul class="small mb-0">
                                <li>
                                    Stanford University. “AI Chatbot Privacy Concerns Underscored in New Research.”
                                    <i>Stanford News</i>, 2025.
                                    Available at: 
                                    <a href="https://news.stanford.edu/stories/2025/10/ai-chatbot-privacy-concerns-risks-research" target="_blank">
                                        https://news.stanford.edu/stories/2025/10/ai-chatbot-privacy-concerns-risks-research
                                    </a>.
                                </li>

                                <li>
                                    Cooley LLP. “AI Chatbots at the Crossroads: Navigating New Laws and Compliance Risks.”
                                    Cooley Insight, 21 Oct 2025.
                                    Available at:
                                    <a href="https://www.cooley.com/news/insight/2025/2025-10-21-ai-chatbots-at-the-crossroads-navigating-new-laws-and-compliance-risks" target="_blank">
                                        https://www.cooley.com/.../ai-chatbots-at-the-crossroads
                                    </a>.
                                </li>

                                <li>
                                    Raine v. OpenAI et al.  
                                    Complaint filed August 2025.  
                                    Available at:
                                    <a href="https://www.courthousenews.com/wp-content/uploads/2025/08/raine-vs-openai-et-al-complaint.pdf" target="_blank">
                                        https://www.courthousenews.com/.../raine-vs-openai-et-al-complaint.pdf
                                    </a>.
                                </li>

                                <li>
                                    Social Media Victims Law Center. “Character.AI Lawsuits.”
                                    Available at:
                                    <a href="https://socialmediavictims.org/character-ai-lawsuits/" target="_blank">
                                        https://socialmediavictims.org/character-ai-lawsuits/
                                    </a>.
                                </li>

                                <li>
                                    California State Senate District 18. “First-in-the-Nation AI Chatbot Safeguards Signed into Law.”
                                    Press release, 2025.
                                    Available at:
                                    <a href="https://sd18.senate.ca.gov/news/first-nation-ai-chatbot-safeguards-signed-law" target="_blank">
                                        https://sd18.senate.ca.gov/.../ai-chatbot-safeguards
                                    </a>.
                                </li>

                                <li>
                                    California Legislature. Senate Bill 243 (2025–2026):  
                                    “AI Safety and Minor Protection Requirements.”  
                                    Available at:
                                    <a href="https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202520260SB243&showamends=false" target="_blank">
                                        https://leginfo.legislature.ca.gov/.../SB243
                                    </a>.
                                </li>
                            </ul>

                        </div>
                    </div>
                </section>
            </section>
        </div>
    </main>

    <!-- Footer -->
    <footer class="py-4 site-footer">
        <div class="container text-center small">
            <p class="mb-1">
                Prepared by Beck Edwards, Vinay Joshi & Rahul Prakash, DSCI 305 (Rice University), 2025.
            </p>
            <p class="mb-0 text-muted tiny">
                This website is an educational project and does not represent official policy or legal advice.
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS (with Popper) -->
    <script
        src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js">
    </script>
</body>
</html>
